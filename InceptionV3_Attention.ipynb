{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Nadam\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, Conv2D, multiply, LocallyConnected2D, Lambda\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "from keras.layers import BatchNormalization\n",
    "from PIL import ImageFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "img_width, img_height = 600, 600\n",
    "train_dir = 'data/train'\n",
    "test_dir = 'data/test'\n",
    "\n",
    "epochs = 15\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1520 images belonging to 2 classes.\n",
      "Found 380 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "def preprocess_input(x):\n",
    "    # 'RGB'->'BGR'\n",
    "    x = x[:, :, ::-1]\n",
    "    # Zero-center by imagenet mean pixel\n",
    "    x[:, :, 0] -= 103.939\n",
    "    x[:, :, 1] -= 116.779\n",
    "    x[:, :, 2] -= 123.68\n",
    "    return x\n",
    "\n",
    "random_seed = np.random.seed(1142)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True,\n",
    "    preprocessing_function = preprocess_input,\n",
    "    validation_split= 0.2,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    subset = 'training',\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    subset = 'validation',\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255, preprocessing_function = preprocess_input)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_train_samples: 1520\n",
      "nb_validation_samples: 380\n",
      "\n",
      "predict_size_train: 190\n",
      "predict_size_validation: 48\n",
      "\n",
      " num_classes: 2\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "nb_train_samples = len(train_generator.filenames)\n",
    "nb_validation_samples = len(validation_generator.filenames)\n",
    "# nb_test_samples = len(test_generator.filenames)\n",
    "\n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
    "# predict_size_test = int(math.ceil(nb_test_samples / batch_size))\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "print(\"nb_train_samples:\", nb_train_samples)\n",
    "print(\"nb_validation_samples:\", nb_validation_samples)\n",
    "# print(\"nb_test_samples:\", nb_test_samples)\n",
    "\n",
    "print(\"\\npredict_size_train:\", predict_size_train)\n",
    "print(\"predict_size_validation:\", predict_size_validation)\n",
    "# print(\"predict_size_test:\", predict_size_test)\n",
    "\n",
    "print(\"\\n num_classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = Input([img_width, img_height, 3])\n",
    "base_pretrained_model = InceptionV3(input_shape = [img_width, img_height, 3], include_top = False, weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 600, 600, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 299, 299, 32) 864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 299, 299, 32) 96          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 299, 299, 32) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 297, 297, 32) 9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 297, 297, 32) 96          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 297, 297, 32) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 297, 297, 64) 18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 297, 297, 64) 192         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 297, 297, 64) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 148, 148, 64) 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 148, 148, 80) 5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 148, 148, 80) 240         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 148, 148, 80) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 146, 146, 192 138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 146, 146, 192 576         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 146, 146, 192 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 72, 72, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 72, 72, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 72, 72, 64)   192         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 72, 72, 64)   0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 72, 72, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 72, 72, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 72, 72, 48)   144         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 72, 72, 96)   288         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 72, 72, 48)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 72, 72, 96)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 72, 72, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 72, 72, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 72, 72, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 72, 72, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 72, 72, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 72, 72, 64)   192         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 72, 72, 64)   192         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 72, 72, 96)   288         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 72, 72, 32)   96          conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 72, 72, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 72, 72, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 72, 72, 96)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 72, 72, 32)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 72, 72, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 72, 72, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 72, 72, 64)   192         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 72, 72, 64)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 72, 72, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 72, 72, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 72, 72, 48)   144         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 72, 72, 96)   288         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 72, 72, 48)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 72, 72, 96)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 72, 72, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 72, 72, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 72, 72, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 72, 72, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 72, 72, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 72, 72, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 72, 72, 64)   192         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 72, 72, 96)   288         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 72, 72, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 72, 72, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 72, 72, 64)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 72, 72, 96)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 72, 72, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 72, 72, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 72, 72, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 72, 72, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 72, 72, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 72, 72, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 72, 72, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 72, 72, 48)   144         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 72, 72, 96)   288         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 72, 72, 48)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 72, 72, 96)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 72, 72, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 72, 72, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 72, 72, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 72, 72, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 72, 72, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 72, 72, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 72, 72, 64)   192         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 72, 72, 96)   288         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 72, 72, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 72, 72, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 72, 72, 64)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 72, 72, 96)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 72, 72, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 72, 72, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 72, 72, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 72, 72, 64)   192         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 72, 72, 64)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 72, 72, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 72, 72, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 72, 72, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 35, 35, 384)  995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 35, 35, 96)   82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 35, 35, 384)  1152        conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 35, 35, 96)   288         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 35, 35, 384)  0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 35, 35, 96)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 35, 35, 288)  0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 35, 35, 768)  0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 35, 35, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 35, 35, 128)  384         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 35, 35, 128)  0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 35, 35, 128)  114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 35, 35, 128)  384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 35, 35, 128)  0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 35, 35, 128)  98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 35, 35, 128)  114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 35, 35, 128)  384         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 35, 35, 128)  384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 35, 35, 128)  0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 35, 35, 128)  0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 35, 35, 128)  114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 35, 35, 128)  114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 35, 35, 128)  384         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 35, 35, 128)  384         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 35, 35, 128)  0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 35, 35, 128)  0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 35, 35, 768)  0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 35, 35, 192)  147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 35, 35, 192)  172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 35, 35, 192)  172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 35, 35, 192)  147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 35, 35, 192)  576         conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 35, 35, 192)  576         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 35, 35, 192)  576         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 35, 35, 192)  576         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 35, 35, 192)  0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 35, 35, 192)  0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 35, 35, 192)  0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 35, 35, 192)  0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 35, 35, 768)  0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 35, 35, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 35, 35, 160)  480         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 35, 35, 160)  0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 35, 35, 160)  179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 35, 35, 160)  480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 35, 35, 160)  0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 35, 35, 160)  122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 35, 35, 160)  179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 35, 35, 160)  480         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 35, 35, 160)  480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 35, 35, 160)  0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 35, 35, 160)  0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 35, 35, 160)  179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 35, 35, 160)  179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 35, 35, 160)  480         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 35, 35, 160)  480         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 35, 35, 160)  0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 35, 35, 160)  0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 35, 35, 768)  0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 35, 35, 192)  147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 35, 35, 192)  215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 35, 35, 192)  215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 35, 35, 192)  147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 35, 35, 192)  576         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 35, 35, 192)  576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 35, 35, 192)  576         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 35, 35, 192)  576         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 35, 35, 192)  0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 35, 35, 192)  0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 35, 35, 192)  0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 35, 35, 192)  0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 35, 35, 768)  0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 35, 35, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 35, 35, 160)  480         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 35, 35, 160)  0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 35, 35, 160)  179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 35, 35, 160)  480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 35, 35, 160)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 35, 35, 160)  122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 35, 35, 160)  179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 35, 35, 160)  480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 35, 35, 160)  480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 35, 35, 160)  0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 35, 35, 160)  0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 35, 35, 160)  179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 35, 35, 160)  179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 35, 35, 160)  480         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 35, 35, 160)  480         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 35, 35, 160)  0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 35, 35, 160)  0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 35, 35, 768)  0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 35, 35, 192)  147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 35, 35, 192)  215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 35, 35, 192)  215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 35, 35, 192)  147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 35, 35, 192)  576         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 35, 35, 192)  576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 35, 35, 192)  576         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 35, 35, 192)  576         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 35, 35, 192)  0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 35, 35, 192)  0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 35, 35, 192)  0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 35, 35, 192)  0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 35, 35, 768)  0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 35, 35, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 35, 35, 192)  576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 35, 35, 192)  0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 35, 35, 192)  258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 35, 35, 192)  576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 35, 35, 192)  0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 35, 35, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 35, 35, 192)  258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 35, 35, 192)  576         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 35, 35, 192)  576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 35, 35, 192)  0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 35, 35, 192)  0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 35, 35, 192)  258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 35, 35, 192)  258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 35, 35, 192)  576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 35, 35, 192)  576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 35, 35, 192)  0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 35, 35, 192)  0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 35, 35, 768)  0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 35, 35, 192)  147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 35, 35, 192)  258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 35, 35, 192)  258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 35, 35, 192)  147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 35, 35, 192)  576         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 35, 35, 192)  576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 35, 35, 192)  576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 35, 35, 192)  576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 35, 35, 192)  0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 35, 35, 192)  0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 35, 35, 192)  0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 35, 35, 192)  0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 35, 35, 768)  0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 35, 35, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 35, 35, 192)  576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 35, 35, 192)  0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 35, 35, 192)  258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 35, 35, 192)  576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 35, 35, 192)  0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 35, 35, 192)  147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 35, 35, 192)  258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 35, 35, 192)  576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 35, 35, 192)  576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 35, 35, 192)  0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 35, 35, 192)  0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 17, 17, 320)  552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 17, 17, 192)  331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 17, 17, 320)  960         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 17, 17, 192)  576         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 17, 17, 320)  0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 17, 17, 192)  0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 17, 17, 768)  0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 17, 17, 1280) 0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 17, 17, 448)  573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 17, 17, 448)  1344        conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 17, 17, 448)  0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 17, 17, 384)  491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 17, 17, 384)  1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 17, 17, 384)  1152        conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 17, 17, 384)  1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 17, 17, 384)  0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 17, 17, 384)  0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 17, 17, 384)  442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 17, 17, 384)  442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 17, 17, 384)  442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 17, 17, 384)  442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 17, 17, 1280) 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 17, 17, 320)  409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 17, 17, 384)  1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 17, 17, 384)  1152        conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 17, 17, 384)  1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 17, 17, 384)  1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 17, 17, 192)  245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 17, 17, 320)  960         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 17, 17, 384)  0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 17, 17, 384)  0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 17, 17, 384)  0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 17, 17, 384)  0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 17, 17, 192)  576         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 17, 17, 320)  0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 17, 17, 768)  0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 17, 17, 768)  0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 17, 17, 192)  0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 17, 17, 2048) 0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 17, 17, 448)  917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 17, 17, 448)  1344        conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 17, 17, 448)  0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 17, 17, 384)  786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 17, 17, 384)  1548288     activation_90[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 17, 17, 384)  1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 17, 17, 384)  1152        conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 17, 17, 384)  0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 17, 17, 384)  0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 17, 17, 384)  442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 17, 17, 384)  442368      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 17, 17, 384)  442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 17, 17, 384)  442368      activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 17, 17, 2048) 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 17, 17, 320)  655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 17, 17, 384)  1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 17, 17, 384)  1152        conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 17, 17, 384)  1152        conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 17, 17, 384)  1152        conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 17, 17, 192)  393216      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 17, 17, 320)  960         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 17, 17, 384)  0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 17, 17, 384)  0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 17, 17, 384)  0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 17, 17, 384)  0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 17, 17, 192)  576         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 17, 17, 320)  0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 17, 17, 768)  0           activation_88[0][0]              \n",
      "                                                                 activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 17, 17, 768)  0           activation_92[0][0]              \n",
      "                                                                 activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 17, 17, 192)  0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 17, 17, 2048) 0           activation_86[0][0]              \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 activation_94[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the pretrained model trainable\n",
    "base_pretrained_model.trainable = True\n",
    "\n",
    "# extract features from pretrained model and feed to attention layers\n",
    "pt_depth = base_pretrained_model.get_output_shape_at(0)[-1]\n",
    "pt_features = base_pretrained_model(input_shape)\n",
    "bn_features = BatchNormalization()(pt_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 600, 600, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "inception_v3 (Model)            (None, 17, 17, 2048) 21802784    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 17, 17, 2048) 8192        inception_v3[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 17, 17, 2048) 0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 17, 17, 64)   131136      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 17, 17, 32)   2080        conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 17, 17, 16)   528         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 17, 17, 8)    136         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 17, 17, 1)    9           conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 17, 17, 2048) 2048        conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, 17, 17, 2048) 0           conv2d_100[0][0]                 \n",
      "                                                                 batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_2 (Glo (None, 2048)         0           conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "RescaleGAP (Lambda)             (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
      "                                                                 global_average_pooling2d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 2048)         0           RescaleGAP[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          262272      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 2)            258         dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,209,443\n",
      "Trainable params: 22,170,915\n",
      "Non-trainable params: 38,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# here we do an attention mechanism to enhance model accuracy\n",
    "attn_layer = Conv2D(64, kernel_size = (1,1), padding = 'same', activation = 'relu')(Dropout(0.5)(bn_features))\n",
    "attn_layer = Conv2D(32, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n",
    "attn_layer = Conv2D(16, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n",
    "attn_layer = Conv2D(8, kernel_size = (1,1), padding = 'same', activation = 'relu')(attn_layer)\n",
    "attn_layer = Conv2D(1, kernel_size = (1,1), padding = 'valid', activation = 'sigmoid')(attn_layer)\n",
    "\n",
    "# distribute to all of the channels\n",
    "up_c2_w = np.ones((1, 1, 1, pt_depth))\n",
    "up_c2 = Conv2D(pt_depth, kernel_size = (1,1), padding = 'same', activation = 'linear', use_bias = False, weights = [up_c2_w])\n",
    "up_c2.trainable = True\n",
    "attn_layer = up_c2(attn_layer)\n",
    "\n",
    "mask_features = multiply([attn_layer, bn_features])\n",
    "gap_features = GlobalAveragePooling2D()(mask_features)\n",
    "gap_mask = GlobalAveragePooling2D()(attn_layer)\n",
    "\n",
    "# to account for missing values from the attention model\n",
    "gap = Lambda(lambda x: x[0]/x[1], name = 'RescaleGAP')([gap_features, gap_mask])\n",
    "gap_dr = Dropout(0.25)(gap)\n",
    "dr_steps = Dropout(0.25)(Dense(128, activation = 'relu')(gap_dr))\n",
    "out_layer = Dense(2, activation = 'softmax')(dr_steps)\n",
    "retina_model = Model(inputs = [input_shape], outputs = [out_layer])\n",
    "\n",
    "retina_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "retina_model.compile(optimizer = Nadam(lr=0.00005), loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.9, patience=10, min_lr=0.000005, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      " - 117s - loss: 0.1353 - acc: 0.8632 - val_loss: 0.4183 - val_acc: 0.7979\n",
      "Epoch 2/15\n",
      " - 102s - loss: 0.0219 - acc: 0.9783 - val_loss: 0.2825 - val_acc: 0.8883\n",
      "Epoch 3/15\n",
      " - 102s - loss: 8.9673e-04 - acc: 1.0000 - val_loss: 0.3896 - val_acc: 0.8590\n",
      "Epoch 4/15\n",
      " - 102s - loss: 0.0173 - acc: 0.9875 - val_loss: 0.5767 - val_acc: 0.8537\n",
      "Epoch 5/15\n",
      " - 102s - loss: 0.0536 - acc: 0.9539 - val_loss: 0.7167 - val_acc: 0.8564\n",
      "Epoch 6/15\n",
      " - 102s - loss: 0.0032 - acc: 1.0000 - val_loss: 0.8032 - val_acc: 0.8564\n",
      "Epoch 7/15\n",
      " - 104s - loss: 8.6782e-04 - acc: 1.0000 - val_loss: 1.1494 - val_acc: 0.8564\n",
      "Epoch 8/15\n",
      " - 103s - loss: 3.1694e-04 - acc: 1.0000 - val_loss: 1.3521 - val_acc: 0.8564\n",
      "Epoch 9/15\n",
      " - 104s - loss: 1.7668e-04 - acc: 1.0000 - val_loss: 1.4889 - val_acc: 0.8564\n",
      "Epoch 10/15\n",
      " - 104s - loss: 1.2513e-04 - acc: 1.0000 - val_loss: 1.4751 - val_acc: 0.8564\n",
      "Epoch 11/15\n",
      " - 104s - loss: 1.4903e-04 - acc: 1.0000 - val_loss: 1.5966 - val_acc: 0.8564\n",
      "Epoch 12/15\n",
      " - 104s - loss: 5.3768e-05 - acc: 1.0000 - val_loss: 1.6321 - val_acc: 0.8564\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 4.499999886320438e-05.\n",
      "Epoch 13/15\n",
      " - 102s - loss: 4.9152e-05 - acc: 1.0000 - val_loss: 1.5996 - val_acc: 0.8564\n",
      "Epoch 14/15\n",
      " - 102s - loss: 6.0944e-05 - acc: 1.0000 - val_loss: 1.6511 - val_acc: 0.8564\n",
      "Epoch 15/15\n",
      " - 105s - loss: 3.5421e-05 - acc: 1.0000 - val_loss: 1.6007 - val_acc: 0.8564\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d23c6ede48>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = {0: 0.366, 1: 0.634}\n",
    "\n",
    "retina_model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    class_weight=weight,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size, verbose=2, callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss:  1.9978591750227817\n",
      "Validation Accuracy:  0.8232323232323232\n"
     ]
    }
   ],
   "source": [
    "score = retina_model.evaluate_generator(validation_generator, steps=50)\n",
    "\n",
    "print ('Validation Loss: ', score[0])\n",
    "print ('Validation Accuracy: ',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 4s 178ms/step\n",
      "No of errors = 25/200\n"
     ]
    }
   ],
   "source": [
    "filename = test_generator.filenames\n",
    "truth = test_generator.classes\n",
    "label = test_generator.class_indices\n",
    "indexlabel = dict((value, key) for key, value in label.items())\n",
    "\n",
    "predicts = retina_model.predict_generator(test_generator, steps=test_generator.samples/test_generator.batch_size, verbose=1)\n",
    "predict_class = np.argmax(predicts, axis=1)\n",
    "errors = np.where(predict_class != truth)[0]\n",
    "print(\"No of errors = {}/{}\".format(len(errors),test_generator.samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[  0  25]\n",
      " [  0 175]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(truth,predict_class)\n",
    "\n",
    "labels = []\n",
    "for k,v in indexlabel.items():\n",
    "    labels.append(v)\n",
    "    \n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion Matrix')\n",
    "\n",
    "    print(cm)\n",
    "#     fig = plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "#     plt.savefig('plots/3.InceptionV3-2-Private-DataSet-CM.png', bbox_inches='tight', dpi = 100) \n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "\n",
    "plot_confusion_matrix(cm, classes=labels,\n",
    "                      title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  25]\n",
      " [  0 175]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "   abnormal       0.00      0.00      0.00        25\n",
      "     normal       0.88      1.00      0.93       175\n",
      "\n",
      "avg / total       0.77      0.88      0.82       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "y_pred = predicts\n",
    "y_pred_probabilities=y_pred\n",
    "\n",
    "y_pred = np.argmax(y_pred,axis = 1) \n",
    "y_actual = test_generator.classes\n",
    "\n",
    "classnames=[]\n",
    "for classname in test_generator.class_indices:\n",
    "    classnames.append(classname)\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_actual, y_pred) \n",
    "print(confusion_mtx)\n",
    "target_names = classnames\n",
    "print(classification_report(y_actual, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.875\n",
      "Sensitivity :  nan\n",
      "Specificity :  0.875\n"
     ]
    }
   ],
   "source": [
    "total=sum(sum(cm))\n",
    "\n",
    "accuracy = (cm[0,0]+cm[1,1]) / total\n",
    "print ('Accuracy : ', accuracy)\n",
    "\n",
    "sensitivity = cm[0,0]/(cm[0,0]+cm[1,0])\n",
    "print('Sensitivity : ', sensitivity )\n",
    "\n",
    "Specificity = cm[1,1]/(cm[1,1]+cm[0,1])\n",
    "print('Specificity : ', Specificity )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8750\n",
      "Precision: 0.8750\n",
      "Recall:    1.0000\n",
      "F1:        0.9333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import classification_report, recall_score\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "th = 0.3\n",
    "\n",
    "acc = accuracy_score(truth,predict_class > th)\n",
    "prec = precision_score(truth,predict_class > th)\n",
    "f1 = f1_score(truth,predict_class > th)\n",
    "recall = recall_score(truth,predict_class > th)\n",
    "\n",
    "print('Accuracy:  {:.4f}'.format(acc))\n",
    "print('Precision: {:.4f}'.format(prec))\n",
    "print('Recall:    {:.4f}'.format(recall))\n",
    "print('F1:        {:.4f}'.format(f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
